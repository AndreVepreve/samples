{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c83fcb2e",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning â€” Companion Notebook\n",
    "This notebook accompanies `introduction_to_machine_learning.md`. It contains runnable code cells, small exercises, and plots.\n",
    "Install prerequisites as needed: `scikit-learn`, `numpy`, `scipy`, `matplotlib`, `pandas`, `imbalanced-learn`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e746d",
   "metadata": {},
   "source": [
    "## 1) Data split & leak-free preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70064992",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(n_samples=5000, n_features=20, n_informative=8,\n",
    "                           weights=[0.85, 0.15], random_state=42)\n",
    "X = pd.DataFrame(X, columns=[f\"f{i}\" for i in range(X.shape[1])])\n",
    "X[\"country\"] = np.random.choice([\"US\",\"DE\",\"IN\",\"BR\"], size=len(X), p=[.4,.2,.25,.15])\n",
    "X[\"device\"] = np.random.choice([\"mobile\",\"desktop\",\"tablet\"], size=len(X), p=[.6,.35,.05])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.mean(), y_test.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9a3efc",
   "metadata": {},
   "source": [
    "## 2) ColumnTransformer + Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa37e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "num_cols = X_train.select_dtypes(np.number).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "])\n",
    "\n",
    "pipe = Pipeline([(\"pre\", pre), (\"model\", LogisticRegression(max_iter=1000))])\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34e2f40",
   "metadata": {},
   "source": [
    "## 3) RandomizedSearchCV on LogisticRegression(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18835319",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_dist = {\"model__C\": loguniform(1e-3, 1e2)}\n",
    "search = RandomizedSearchCV(pipe, param_distributions=param_dist,\n",
    "                            n_iter=30, cv=cv, scoring=\"f1\", n_jobs=-1, random_state=42)\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_, search.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b855c",
   "metadata": {},
   "source": [
    "## 4) Metrics & calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead76208",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, average_precision_score, brier_score_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "\n",
    "best = search.best_estimator_\n",
    "cal = CalibratedClassifierCV(best, cv=3)  # isotonic by default\n",
    "cal.fit(X_train, y_train)\n",
    "\n",
    "proba = cal.predict_proba(X_test)[:,1]\n",
    "pred  = (proba >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, proba))\n",
    "print(\"Brier:\", brier_score_loss(y_test, proba))\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y_test, proba)\n",
    "ap = average_precision_score(y_test, proba)\n",
    "ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reliability diagram\n",
    "import matplotlib.pyplot as plt\n",
    "prob_true, prob_pred = calibration_curve(y_test, proba, n_bins=10, strategy=\"quantile\")\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='isotonic-calibrated')\n",
    "plt.plot([0,1],[0,1],'--',alpha=.5,color='gray')\n",
    "plt.xlabel(\"Predicted probability\"); plt.ylabel(\"Empirical frequency\"); plt.legend(); plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5229f4",
   "metadata": {},
   "source": [
    "## 5) Imbalanced tactics: SMOTE + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f4468",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "smote_logreg = make_pipeline(\n",
    "    SMOTE(k_neighbors=5, random_state=42),\n",
    "    LogisticRegression(max_iter=1000)\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "p = smote_logreg.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test, p), average_precision_score(y_test, p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0770efd",
   "metadata": {},
   "source": [
    "## 6) Model interpretation: permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e6fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "r = permutation_importance(cal, X_test, y_test, n_repeats=10, scoring=\"roc_auc\", random_state=42)\n",
    "np.vstack([X_test.columns, r.importances_mean, r.importances_std]).T[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbfc97e",
   "metadata": {},
   "source": [
    "## 7) Unsupervised starter: KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de9bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "km = make_pipeline(StandardScaler(), KMeans(n_clusters=8, n_init=\"auto\", random_state=42))\n",
    "labels = km.fit_predict(X_train.select_dtypes(np.number))\n",
    "km[-1].inertia_, np.bincount(labels)[:8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bbadac",
   "metadata": {},
   "source": [
    "## 8) Learning & validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a2a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "sizes, tr, va = learning_curve(best, X_train, y_train, cv=3, scoring=\"roc_auc\",\n",
    "                               train_sizes=np.linspace(0.1,1.0,5), n_jobs=-1, random_state=42)\n",
    "param_range = np.logspace(-3, 2, 8)\n",
    "tr_v, va_v = validation_curve(pipe, X_train, y_train, param_name=\"model__C\",\n",
    "                              param_range=param_range, cv=3, scoring=\"f1\", n_jobs=-1)\n",
    "sizes[:3], tr.mean(axis=1)[:3], va.mean(axis=1)[:3]\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}